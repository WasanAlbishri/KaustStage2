{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjtYtFQpVSeJUKRWQfeTh+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WasanAlbishri/KaustStage2/blob/main/NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opk72XOPq0m3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms.functional import to_tensor\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "If you have your own data, you can still apply the same general approach to building a neural network. However, working with your own dataset introduces additional considerations for data preprocessing, model design, and evaluation. Here’s a step-by-step guide to using your own data for training a neural network:\n",
        "\n",
        "1. Understand Your Data\n",
        "Before jumping into building a neural network, it's important to thoroughly understand the characteristics of your data.\n",
        "\n",
        "What type of data is it?\n",
        "\n",
        "Tabular data (e.g., CSV files with rows and columns, numerical and categorical features).\n",
        "Images (e.g., PNG, JPG).\n",
        "Text (e.g., plain text, CSV with text data).\n",
        "Time series (e.g., stock prices, sensor readings).\n",
        "What is the task you're solving?\n",
        "\n",
        "Classification: You have categories or classes (e.g., \"spam\" or \"not spam\").\n",
        "Regression: You predict a continuous value (e.g., house prices, temperature).\n",
        "Clustering: You want to group data into clusters without labeled classes.\n",
        "Do you have labeled data?\n",
        "\n",
        "Supervised learning: You have input-output pairs (e.g., image and its label).\n",
        "Unsupervised learning: You only have inputs (e.g., clustering data or anomaly detection).\n",
        "2. Preprocess Your Data\n",
        "Data preprocessing is essential to prepare your data for neural network training. Steps will vary based on your data type.\n",
        "\n",
        "For Tabular Data:\n",
        "Handle missing values:\n",
        "\n",
        "You can either drop rows/columns with missing values or fill them with mean, median, or a constant value.\n",
        "Example (in Python):\n",
        "python\n",
        "Copy code\n",
        "import pandas as pd\n",
        "data = pd.read_csv('your_data.csv')\n",
        "data.fillna(data.mean(), inplace=True)\n",
        "Normalize or Standardize data:\n",
        "\n",
        "Neural networks generally work better when data is on a similar scale.\n",
        "Normalization: Scale features to a range [0, 1].\n",
        "Standardization: Scale features to have a mean of 0 and a standard deviation of 1.\n",
        "Example (in Python):\n",
        "python\n",
        "Copy code\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "Convert categorical variables:\n",
        "\n",
        "One-hot encoding for categorical variables.\n",
        "Example (in Python):\n",
        "python\n",
        "Copy code\n",
        "data = pd.get_dummies(data, columns=['category_column'])\n",
        "For Image Data:\n",
        "Resize images: Neural networks expect input images to have the same size.\n",
        "Data augmentation: Augment your data (rotation, flipping, scaling) to avoid overfitting.\n",
        "Example (in Python with Keras):\n",
        "python\n",
        "Copy code\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "For Text Data:\n",
        "Tokenization: Convert text into sequences of tokens (words or characters).\n",
        "Padding: Ensure all input sequences have the same length.\n",
        "Example (in Python with Keras):\n",
        "python\n",
        "Copy code\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(text_data)\n",
        "sequences = tokenizer.texts_to_sequences(text_data)\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_sequences = pad_sequences(sequences, maxlen=100)\n",
        "For Time Series Data:\n",
        "Windowing: Convert time series data into windows (segments) for prediction.\n",
        "For example, use the past N time steps to predict the next time step.\n",
        "Normalization: Like tabular data, it’s important to normalize your time series data.\n",
        "3. Split Your Data\n",
        "You should split your data into three sets:\n",
        "\n",
        "Training set: Used to train the model.\n",
        "Validation set: Used to tune hyperparameters and avoid overfitting.\n",
        "Test set: Used to evaluate the final model performance.\n",
        "A typical split is 70-80% for training, 10-15% for validation, and 10-15% for testing.\n",
        "\n",
        "Example (in Python):\n",
        "\n",
        "python\n",
        "Copy code\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5)\n",
        "4. Define Your Model Architecture\n",
        "Now that your data is preprocessed and split, you need to define the neural network model architecture.\n",
        "\n",
        "Input layer: Matches the shape of your input data.\n",
        "Hidden layers: Layers where the actual learning happens. You can use fully connected (Dense) layers, convolutional (Conv) layers for images, or recurrent layers (RNN/LSTM) for sequential data.\n",
        "Output layer: The size of this layer depends on your task:\n",
        "For classification: Use a softmax activation function (for multi-class) or sigmoid (for binary classification).\n",
        "For regression: Use a linear activation function.\n",
        "Example for a Simple Feedforward Neural Network (Tabular Data):\n",
        "python\n",
        "Copy code\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    Dense(128, input_dim=X_train.shape[1], activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
        "Example for a Convolutional Neural Network (CNN) (Image Data):\n",
        "python\n",
        "Copy code\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')  # For 10 classes\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
        "5. Train and Evaluate the Model\n",
        "Once the model is defined, you can train it on your training data and evaluate it on the test set.\n",
        "\n",
        "Monitoring performance: Keep track of training and validation loss/accuracy to ensure the model is learning properly.\n",
        "Overfitting: If your model is overfitting, consider:\n",
        "Adding regularization (e.g., L2 regularization).\n",
        "Using Dropout layers.\n",
        "Early stopping to stop training when the validation loss stops improving.\n",
        "Example of Evaluating:\n",
        "python\n",
        "Copy code\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc}\")\n",
        "6. Hyperparameter Tuning\n",
        "If your model isn’t performing well, you can:\n",
        "\n",
        "Tune hyperparameters: Try adjusting the number of layers, neurons per layer, learning rate, batch size, etc.\n",
        "Use cross-validation: For a more robust evaluation of the model’s performance across different data splits.\n",
        "7. Deploying the Model\n",
        "Once you're satisfied with your model’s performance, you can deploy it into a production environment for real-time predictions.\n",
        "\n",
        "Save the model: You can save your trained model using the model.save() method (in Keras).\n",
        "Load the model: In production, you can load it with tf.keras.models.load_model() to make predictions on new data.\n",
        "Additional Tips:\n",
        "Data imbalance: If you have an imbalanced dataset (e.g., more negative samples than positive), consider techniques like oversampling, undersampling, or class weights.\n",
        "Model evaluation: Use metrics such as precision, recall, F1-score for classification tasks, especially if the data is imbalanced.\n"
      ],
      "metadata": {
        "id": "OGhOuWwRrLgT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}